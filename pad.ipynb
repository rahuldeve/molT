{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from sklearn import metrics\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers.trainer_utils import SchedulerType\n",
    "from functools import partial\n",
    "\n",
    "from data import generate_and_scale_mol_descriptors\n",
    "from molT import (\n",
    "    DataCollatorForMaskedMolecularModeling,\n",
    "    MolTConfig,\n",
    "    MolTForMaskedMM,\n",
    "    MolTTokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import rdkit.Chem as Chem\n",
    "# smiles = 'CC'\n",
    "# from rdkit.Chem.Descriptors import CalcMolDescriptors\n",
    "# mol = Chem.MolFromSmiles(smiles)\n",
    "# CalcMolDescriptors(mol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = MolTConfig()\n",
    "tokenizer = MolTTokenizer(model_config)\n",
    "model = MolTForMaskedMM(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = (\n",
    "    load_dataset(\"sagawa/ZINC-canonicalized\")[\"validation\"]\n",
    "    .select(range(100))\n",
    "    .train_test_split(seed=42)\n",
    ")\n",
    "\n",
    "ds, _ = generate_and_scale_mol_descriptors(ds, model_config.mol_descriptors, num_samples=50, num_proc=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(entry, tokenizer):\n",
    "    entry = dict(entry)\n",
    "    smiles = entry.pop('smiles')\n",
    "    return tokenizer(smiles, truncation=False, return_attention_mask=True, return_special_tokens_mask=True, **entry)\n",
    "\n",
    "tok_func = partial(tokenize, tokenizer=tokenizer)\n",
    "ds = ds.map(tok_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_metrics(eval_pred):\n",
    "    (\n",
    "        mm_loss,\n",
    "        atom_prop_loss,\n",
    "        bond_prop_loss,\n",
    "        mol_desc_loss,\n",
    "        target_loss,\n",
    "        target_mask,\n",
    "        pred_target_values,\n",
    "        true_target_values,\n",
    "    ) = eval_pred.predictions\n",
    "\n",
    "    target_mask[target_mask == -100] = 0\n",
    "    target_mask = target_mask.astype(bool)\n",
    "    pred_target_values[~target_mask] = 0.0\n",
    "    true_target_values[~target_mask] = 0.0\n",
    "\n",
    "    y_true = true_target_values[target_mask]\n",
    "    y_pred = pred_target_values[target_mask]\n",
    "\n",
    "    r2_score = metrics.r2_score(y_true, y_pred)\n",
    "    mae = metrics.mean_absolute_error(y_true, y_pred)\n",
    "    mse = metrics.mean_squared_error(y_true, y_pred)\n",
    "\n",
    "    return {\n",
    "        \"mm_loss\": mm_loss.mean(),\n",
    "        \"atom_prop_loss\": atom_prop_loss.mean(),\n",
    "        \"bond_prop_loss\": bond_prop_loss.mean(),\n",
    "        \"mol_desc_loss\": mol_desc_loss.mean(),\n",
    "        \"target_loss\": target_loss.mean(),\n",
    "        \"target_r2\": r2_score,\n",
    "        \"target_mae\": mae,\n",
    "        \"target_mse\": mse,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"molT_runs\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    learning_rate=2e-4,\n",
    "    num_train_epochs=4,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    "    logging_steps=1,\n",
    "    eval_steps=1,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    # gradient_accumulation_steps=16,\n",
    "    warmup_ratio=0.1,\n",
    "    # report_to=\"wandb\",\n",
    "    # dataloader_num_workers=8,\n",
    "    lr_scheduler_type=SchedulerType.COSINE,\n",
    "    data_seed=42,\n",
    "    run_name=\"molt_dev_v2\",\n",
    "    # dataloader_pin_memory=True,\n",
    "    # bf16=True,\n",
    "    # bf16_full_eval=True,\n",
    ")\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator = DataCollatorForMaskedMolecularModeling(tokenizer=tokenizer, mlm_probability=0.15)\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=ds[\"train\"],\n",
    "    eval_dataset=ds[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=fn_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
