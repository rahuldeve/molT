{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from sklearn import metrics\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers.trainer_utils import SchedulerType\n",
    "\n",
    "from data import generate_and_scale_mol_descriptors\n",
    "from molT import (\n",
    "    DataCollatorForMaskedMolecularModeling,\n",
    "    MolTConfig,\n",
    "    MolTForMaskedMM,\n",
    "    MolTTokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import rdkit.Chem as Chem\n",
    "# smiles = 'CC'\n",
    "# from rdkit.Chem.Descriptors import CalcMolDescriptors\n",
    "# mol = Chem.MolFromSmiles(smiles)\n",
    "# CalcMolDescriptors(mol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = MolTConfig()\n",
    "tokenizer = MolTTokenizer(model_config)\n",
    "model = MolTForMaskedMM(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e1086abfbcd4534a072f5a9da0c21cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/3750 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4b0b51536ff4d51ad49b4adf6a5f1ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/1250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize(entry, tokenizer):\n",
    "    entry = dict(entry)\n",
    "    smiles = entry.pop(\"smiles\")\n",
    "    return tokenizer(\n",
    "        smiles,\n",
    "        truncation=False,\n",
    "        return_attention_mask=True,\n",
    "        return_special_tokens_mask=True,\n",
    "        **entry,\n",
    "    )\n",
    "\n",
    "ds = (\n",
    "    load_dataset(\"sagawa/ZINC-canonicalized\")[\"validation\"]\n",
    "    .select(range(300_000))\n",
    "    .train_test_split(seed=42)\n",
    ")\n",
    "\n",
    "ds, _ = generate_and_scale_mol_descriptors(\n",
    "    ds, model_config.mol_descriptors, num_samples=100_000, num_proc=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_metrics(eval_pred):\n",
    "    (\n",
    "        mm_loss,\n",
    "        atom_prop_loss,\n",
    "        bond_prop_loss,\n",
    "        mol_desc_loss,\n",
    "        target_loss,\n",
    "        target_mask,\n",
    "        pred_target_values,\n",
    "        true_target_values,\n",
    "    ) = eval_pred.predictions\n",
    "\n",
    "    target_mask[target_mask == -100] = 0\n",
    "    target_mask = target_mask.astype(bool)\n",
    "    pred_target_values[~target_mask] = 0.0\n",
    "    true_target_values[~target_mask] = 0.0\n",
    "\n",
    "    y_true = true_target_values[target_mask]\n",
    "    y_pred = pred_target_values[target_mask]\n",
    "\n",
    "    r2_score = metrics.r2_score(y_true, y_pred)\n",
    "    mae = metrics.mean_absolute_error(y_true, y_pred)\n",
    "    mse = metrics.mean_squared_error(y_true, y_pred)\n",
    "\n",
    "    return {\n",
    "        \"mm_loss\": mm_loss.mean(),\n",
    "        \"atom_prop_loss\": atom_prop_loss.mean(),\n",
    "        \"bond_prop_loss\": bond_prop_loss.mean(),\n",
    "        \"mol_desc_loss\": mol_desc_loss.mean(),\n",
    "        \"target_loss\": target_loss.mean(),\n",
    "        \"target_r2\": r2_score,\n",
    "        \"target_mae\": mae,\n",
    "        \"target_mse\": mse,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2e249a1fbbf4dd192eef2fde6900598",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 21.8381, 'learning_rate': 0.00013333333333333334, 'epoch': 1.08}\n",
      "{'loss': 69.4462, 'learning_rate': 0.0, 'epoch': 2.17}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f8d73bbb8584af9ab31b86620c27c5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 28.63437843322754, 'eval_mm_loss': 2.345188856124878, 'eval_atom_prop_loss': 2.382370710372925, 'eval_bond_prop_loss': 1.6494123935699463, 'eval_mol_desc_loss': 2179.296875, 'eval_runtime': 9.466, 'eval_samples_per_second': 132.052, 'eval_steps_per_second': 4.226, 'epoch': 2.17}\n",
      "{'train_runtime': 152.2793, 'train_samples_per_second': 98.503, 'train_steps_per_second': 0.026, 'train_loss': 45.64213275909424, 'epoch': 2.17}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4, training_loss=45.64213275909424, metrics={'train_runtime': 152.2793, 'train_samples_per_second': 98.503, 'train_steps_per_second': 0.026, 'train_loss': 45.64213275909424, 'epoch': 2.17})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"molT_runs\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    learning_rate=2e-4,\n",
    "    num_train_epochs=4,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    "    logging_steps=8,\n",
    "    eval_steps=32,\n",
    "    per_device_train_batch_size=128,\n",
    "    per_device_eval_batch_size=128,\n",
    "    gradient_accumulation_steps=16,\n",
    "    warmup_ratio=0.1,\n",
    "    report_to=\"wandb\",\n",
    "    dataloader_num_workers=8,\n",
    "    lr_scheduler_type=SchedulerType.COSINE,\n",
    "    data_seed=42,\n",
    "    run_name=\"molt_dev_v2\",\n",
    "    dataloader_pin_memory=True,\n",
    "    bf16=True,\n",
    "    bf16_full_eval=True,\n",
    ")\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator = DataCollatorForMaskedMolecularModeling(tokenizer=tokenizer, mlm_probability=0.15)\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=ds[\"train\"],\n",
    "    eval_dataset=ds[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=fn_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
